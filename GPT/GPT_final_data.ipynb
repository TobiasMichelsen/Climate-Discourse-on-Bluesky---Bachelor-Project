{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in /Users/tobiasmichelsen/Library/Python/3.9/lib/python/site-packages (0.28.1)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/tobiasmichelsen/Library/Python/3.9/lib/python/site-packages (from openai) (2.32.3)\n",
      "Requirement already satisfied: aiohttp in /Users/tobiasmichelsen/Library/Python/3.9/lib/python/site-packages (from openai) (3.11.16)\n",
      "Requirement already satisfied: tqdm in /Users/tobiasmichelsen/Library/Python/3.9/lib/python/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tobiasmichelsen/Library/Python/3.9/lib/python/site-packages (from requests>=2.20->openai) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tobiasmichelsen/Library/Python/3.9/lib/python/site-packages (from requests>=2.20->openai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/tobiasmichelsen/Library/Python/3.9/lib/python/site-packages (from requests>=2.20->openai) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tobiasmichelsen/Library/Python/3.9/lib/python/site-packages (from requests>=2.20->openai) (2025.1.31)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/tobiasmichelsen/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai) (0.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/tobiasmichelsen/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai) (25.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/tobiasmichelsen/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai) (1.3.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/tobiasmichelsen/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai) (2.6.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/tobiasmichelsen/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai) (6.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/tobiasmichelsen/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai) (5.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/tobiasmichelsen/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai) (1.19.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/tobiasmichelsen/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai) (1.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /Users/tobiasmichelsen/Library/Python/3.9/lib/python/site-packages (from multidict<7.0,>=4.5->aiohttp->openai) (4.12.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = \"/Users/tobiasmichelsen/Bachelor_Project/DS_BachelorProject_PH/data/BERTopicResult/BERTopic_final_result.json\"\n",
    "OUTPUT_DIR = Path(\"/Users/tobiasmichelsen/Bachelor_Project/DS_BachelorProject_PH/data/llm_subtopic/single_label/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE_MULTI = \"\"\"\n",
    "You are a helpful assistant that classifies text into one or more climate-related categories.\n",
    "\n",
    "Use the examples below to guide your classification:\n",
    "\n",
    "- Activism: \"Thousands marched in the climate strike demanding government action.\", \"Youth-led campaigns are pressuring lawmakers to enact stronger climate policies.\", \"Environmental activists chained themselves to construction equipment to protest deforestation.\"\n",
    "- Agriculture: \"Crops are failing due to prolonged droughts intensified by climate change.\", \"Pollinators like bees are disappearing, threatening global food security.\", \"Rising temperatures are affecting livestock health and reducing dairy production on farms.\"\n",
    "- Disaster: \"Wildfires have devastated thousands of acres in California.\", \"Flooding from intense storms has displaced hundreds of families across the region.\", \"A powerful hurricane made landfall, causing widespread destruction and power outages.\"\n",
    "- Fossil: \"Oil prices continue to rise amid geopolitical tensions and supply constraints.\", \"New coal-fired power plants are being built despite international climate agreements.\", \"Natural gas usage has surged as countries transition away from coal and nuclear energy.\"\n",
    "- Lifestyle: \"People are embracing minimalist living to reduce their carbon footprint.\", \"Plant-based diets are gaining popularity for their environmental benefits.\", \"Air pollution is linked to rising asthma rates in urban areas.\"\n",
    "- Politics: \"The new administration reversed several environmental protections.\", \"Communities of color are disproportionately affected by environmental hazards.\", \"Lawmakers are debating a new bill aimed at cutting national carbon emissions by 2030.\"\n",
    "- Renewable: \"Government subsidies are making rooftop solar panels more accessible.\", \"Community wind projects are helping rural areas become energy independent.\", \"Drought conditions are affecting the electricity output of hydropower plants in Brazil.\"\n",
    "- Waste: \"Cities are expanding composting and recycling programs to reduce landfill use.\", \"Single-use plastics are being banned in several countries to combat environmental pollution.\", \"Innovative startups are turning food waste into sustainable packaging materials.\"\n",
    "- Weather: \"Global temperatures hit a new record high this year.\", \"An unprecedented heatwave swept across Europe, breaking temperature records.\", \"Heavy rainfall and flash floods have disrupted transportation in the region.\"\n",
    "- Nature: \"Biodiversity is very important for a healthy ecosystem and we should be looking after wildlife.\", \"Mass extinction of plants and animals is a real danger we have to consider\", \"Trees are magnificent creatures and I believe are a key element in combating climate change.\"\n",
    "- Nuclear: \"Nuclear energy is key for our future as we transition to low-carbon power sources.\", \"Debates continue over the safety and waste management of nuclear power plants.\", \"Several countries are investing in next-generation nuclear reactors to meet climate goals.\"\n",
    "- Electricity: \"Electricity demand is expected to surge with the rise of electric vehicles and heat pumps.\", \"Power outages are becoming more frequent due to aging electrical grids and extreme weather.\", \"Renewables now supply a growing share of global electricity production.\"\n",
    "- Construction: \"Green construction practices are reducing the carbon footprint of new buildings.\", \"Urban expansion is driving increased demand for sustainable construction materials.\", \"The construction industry faces pressure to cut emissions and improve energy efficiency.\"\n",
    "- Transportation: \"Public transportation systems are expanding to reduce urban congestion and pollution.\", \"Electric vehicles are transforming the future of transportation infrastructure.\", \"Transportation remains a major source of greenhouse gas emissions globally.\"\n",
    "\n",
    "\n",
    "If the text belongs to more than one category, list all relevant categories. If the text does not fit any category above, assign a new category name.\n",
    "\n",
    "Classify the following text:\n",
    "\"{text}\"\n",
    "\n",
    "Respond with one or more category names only, separated by commas. Do not include quotation marks or explanations.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE_SINGLE = \"\"\"\n",
    "You are a helpful assistant that classifies text into exactly one climate-related categories.\n",
    "\n",
    "Use the examples below to guide your classification:\n",
    "\n",
    "- Activism: \"Thousands marched in the climate strike demanding government action.\", \"Youth-led campaigns are pressuring lawmakers to enact stronger climate policies.\", \"Environmental activists chained themselves to construction equipment to protest deforestation.\"\n",
    "- Agriculture: \"Crops are failing due to prolonged droughts intensified by climate change.\", \"Pollinators like bees are disappearing, threatening global food security.\", \"Rising temperatures are affecting livestock health and reducing dairy production on farms.\"\n",
    "- Disaster: \"Wildfires have devastated thousands of acres in California.\", \"Flooding from intense storms has displaced hundreds of families across the region.\", \"A powerful hurricane made landfall, causing widespread destruction and power outages.\"\n",
    "- Fossil: \"Oil prices continue to rise amid geopolitical tensions and supply constraints.\", \"New coal-fired power plants are being built despite international climate agreements.\", \"Natural gas usage has surged as countries transition away from coal and nuclear energy.\"\n",
    "- Lifestyle: \"People are embracing minimalist living to reduce their carbon footprint.\", \"Plant-based diets are gaining popularity for their environmental benefits.\", \"Air pollution is linked to rising asthma rates in urban areas.\"\n",
    "- Politics: \"The new administration reversed several environmental protections.\", \"Communities of color are disproportionately affected by environmental hazards.\", \"Lawmakers are debating a new bill aimed at cutting national carbon emissions by 2030.\"\n",
    "- Renewable: \"Government subsidies are making rooftop solar panels more accessible.\", \"Community wind projects are helping rural areas become energy independent.\", \"Drought conditions are affecting the electricity output of hydropower plants in Brazil.\"\n",
    "- Waste: \"Cities are expanding composting and recycling programs to reduce landfill use.\", \"Single-use plastics are being banned in several countries to combat environmental pollution.\", \"Innovative startups are turning food waste into sustainable packaging materials.\"\n",
    "- Weather: \"Global temperatures hit a new record high this year.\", \"An unprecedented heatwave swept across Europe, breaking temperature records.\", \"Heavy rainfall and flash floods have disrupted transportation in the region.\"\n",
    "- Nature: \"Biodiversity is very important for a healthy ecosystem and we should be looking after wildlife.\", \"Mass extinction of plants and animals is a real danger we have to consider\", \"Trees are magnificent creatures and I believe are a key element in combating climate change.\"\n",
    "- Nuclear: \"Nuclear energy is key for our future as we transition to low-carbon power sources.\", \"Debates continue over the safety and waste management of nuclear power plants.\", \"Several countries are investing in next-generation nuclear reactors to meet climate goals.\"\n",
    "- Electricity: \"Electricity demand is expected to surge with the rise of electric vehicles and heat pumps.\", \"Power outages are becoming more frequent due to aging electrical grids and extreme weather.\", \"Renewables now supply a growing share of global electricity production.\"\n",
    "- Construction: \"Green construction practices are reducing the carbon footprint of new buildings.\", \"Urban expansion is driving increased demand for sustainable construction materials.\", \"The construction industry faces pressure to cut emissions and improve energy efficiency.\"\n",
    "- Transportation: \"Public transportation systems are expanding to reduce urban congestion and pollution.\", \"Electric vehicles are transforming the future of transportation infrastructure.\", \"Transportation remains a major source of greenhouse gas emissions globally.\"\n",
    "\n",
    "\n",
    "If the text does not fit any category above, assign a new category name.\n",
    "\n",
    "Classify the following text:\n",
    "\"{text}\"\n",
    "\n",
    "Respond with only the category name. Do not include quotation marks or explanations.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_n(df, max_n=20):\n",
    "    N = len(df)\n",
    "    Z = 1.96\n",
    "    p = 0.5\n",
    "    E = 0.05\n",
    "    n = round((N * Z**2 * p * (1 - p)) / ((E**2 * (N - 1)) + (Z**2 * p * (1 - p))))\n",
    "    return min(n, max_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(INPUT_PATH, lines=True)\n",
    "df = df.rename(columns={\"topic\": \"cluster\"}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classification(df):\n",
    "    for cluster_id in df.cluster.unique():\n",
    "        df_cl = df[df.cluster == cluster_id]\n",
    "        n = calculate_n(df_cl)\n",
    "        df_samp = df_cl.sample(n=n, random_state=42)\n",
    "\n",
    "        topic_data = {\n",
    "            \"topic\": int(cluster_id),\n",
    "            \"samples\": []\n",
    "        }\n",
    "\n",
    "        for idx, row in df_samp.reset_index(drop=True).iterrows():\n",
    "            prompt = PROMPT_TEMPLATE_SINGLE.format(text=row[\"text\"])\n",
    "\n",
    "            try:\n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                    ],\n",
    "                    temperature=0.0,\n",
    "                    max_tokens=50\n",
    "                )\n",
    "                label = response.choices[0].message.content.strip()\n",
    "            except Exception as e:\n",
    "                label = f\"ERROR: {str(e)}\"\n",
    "\n",
    "            topic_data[\"samples\"].append({\n",
    "                \"cid\": row.get(\"cid\"),\n",
    "                \"text\": row[\"text\"],\n",
    "                \"gpt_label\": label\n",
    "            })\n",
    "\n",
    "            if idx % 5 == 0:\n",
    "                print(f\"[Cluster {cluster_id}] Processed {idx + 1}/{n} samples\")\n",
    "\n",
    "        topic_dir = OUTPUT_DIR\n",
    "        topic_dir.mkdir(parents=True, exist_ok=True)\n",
    "        topic_file = topic_dir / f\"topic_{str(cluster_id).zfill(4)}.json\"\n",
    "        with open(topic_file, \"w\") as f:\n",
    "            json.dump(topic_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Cluster 7] Processed 1/20 samples\n",
      "[Cluster 7] Processed 6/20 samples\n",
      "[Cluster 7] Processed 11/20 samples\n",
      "[Cluster 7] Processed 16/20 samples\n",
      "[Cluster 0] Processed 1/20 samples\n",
      "[Cluster 0] Processed 6/20 samples\n",
      "[Cluster 0] Processed 11/20 samples\n",
      "[Cluster 0] Processed 16/20 samples\n",
      "[Cluster 3] Processed 1/20 samples\n",
      "[Cluster 3] Processed 6/20 samples\n",
      "[Cluster 3] Processed 11/20 samples\n",
      "[Cluster 3] Processed 16/20 samples\n",
      "[Cluster 9] Processed 1/20 samples\n",
      "[Cluster 9] Processed 6/20 samples\n",
      "[Cluster 9] Processed 11/20 samples\n",
      "[Cluster 9] Processed 16/20 samples\n",
      "[Cluster 1] Processed 1/20 samples\n",
      "[Cluster 1] Processed 6/20 samples\n",
      "[Cluster 1] Processed 11/20 samples\n",
      "[Cluster 1] Processed 16/20 samples\n",
      "[Cluster 12] Processed 1/20 samples\n",
      "[Cluster 12] Processed 6/20 samples\n",
      "[Cluster 12] Processed 11/20 samples\n",
      "[Cluster 12] Processed 16/20 samples\n",
      "[Cluster 4] Processed 1/20 samples\n",
      "[Cluster 4] Processed 6/20 samples\n",
      "[Cluster 4] Processed 11/20 samples\n",
      "[Cluster 4] Processed 16/20 samples\n",
      "[Cluster 16] Processed 1/20 samples\n",
      "[Cluster 16] Processed 6/20 samples\n",
      "[Cluster 16] Processed 11/20 samples\n",
      "[Cluster 16] Processed 16/20 samples\n",
      "[Cluster 14] Processed 1/20 samples\n",
      "[Cluster 14] Processed 6/20 samples\n",
      "[Cluster 14] Processed 11/20 samples\n",
      "[Cluster 14] Processed 16/20 samples\n",
      "[Cluster 13] Processed 1/20 samples\n",
      "[Cluster 13] Processed 6/20 samples\n",
      "[Cluster 13] Processed 11/20 samples\n",
      "[Cluster 13] Processed 16/20 samples\n",
      "[Cluster 5] Processed 1/20 samples\n",
      "[Cluster 5] Processed 6/20 samples\n",
      "[Cluster 5] Processed 11/20 samples\n",
      "[Cluster 5] Processed 16/20 samples\n",
      "[Cluster 22] Processed 1/20 samples\n",
      "[Cluster 22] Processed 6/20 samples\n",
      "[Cluster 22] Processed 11/20 samples\n",
      "[Cluster 22] Processed 16/20 samples\n",
      "[Cluster 29] Processed 1/20 samples\n",
      "[Cluster 29] Processed 6/20 samples\n",
      "[Cluster 29] Processed 11/20 samples\n",
      "[Cluster 29] Processed 16/20 samples\n",
      "[Cluster 33] Processed 1/20 samples\n",
      "[Cluster 33] Processed 6/20 samples\n",
      "[Cluster 33] Processed 11/20 samples\n",
      "[Cluster 33] Processed 16/20 samples\n",
      "[Cluster 39] Processed 1/20 samples\n",
      "[Cluster 39] Processed 6/20 samples\n",
      "[Cluster 39] Processed 11/20 samples\n",
      "[Cluster 39] Processed 16/20 samples\n",
      "[Cluster 25] Processed 1/20 samples\n",
      "[Cluster 25] Processed 6/20 samples\n",
      "[Cluster 25] Processed 11/20 samples\n",
      "[Cluster 25] Processed 16/20 samples\n",
      "[Cluster 2] Processed 1/20 samples\n",
      "[Cluster 2] Processed 6/20 samples\n",
      "[Cluster 2] Processed 11/20 samples\n",
      "[Cluster 2] Processed 16/20 samples\n",
      "[Cluster 8] Processed 1/20 samples\n",
      "[Cluster 8] Processed 6/20 samples\n",
      "[Cluster 8] Processed 11/20 samples\n",
      "[Cluster 8] Processed 16/20 samples\n",
      "[Cluster 15] Processed 1/20 samples\n",
      "[Cluster 15] Processed 6/20 samples\n",
      "[Cluster 15] Processed 11/20 samples\n",
      "[Cluster 15] Processed 16/20 samples\n",
      "[Cluster 6] Processed 1/20 samples\n",
      "[Cluster 6] Processed 6/20 samples\n",
      "[Cluster 6] Processed 11/20 samples\n",
      "[Cluster 6] Processed 16/20 samples\n",
      "[Cluster 20] Processed 1/20 samples\n",
      "[Cluster 20] Processed 6/20 samples\n",
      "[Cluster 20] Processed 11/20 samples\n",
      "[Cluster 20] Processed 16/20 samples\n",
      "[Cluster 41] Processed 1/20 samples\n",
      "[Cluster 41] Processed 6/20 samples\n",
      "[Cluster 41] Processed 11/20 samples\n",
      "[Cluster 41] Processed 16/20 samples\n",
      "[Cluster 35] Processed 1/20 samples\n",
      "[Cluster 35] Processed 6/20 samples\n",
      "[Cluster 35] Processed 11/20 samples\n",
      "[Cluster 35] Processed 16/20 samples\n",
      "[Cluster 19] Processed 1/20 samples\n",
      "[Cluster 19] Processed 6/20 samples\n",
      "[Cluster 19] Processed 11/20 samples\n",
      "[Cluster 19] Processed 16/20 samples\n",
      "[Cluster 32] Processed 1/20 samples\n",
      "[Cluster 32] Processed 6/20 samples\n",
      "[Cluster 32] Processed 11/20 samples\n",
      "[Cluster 32] Processed 16/20 samples\n",
      "[Cluster 10] Processed 1/20 samples\n",
      "[Cluster 10] Processed 6/20 samples\n",
      "[Cluster 10] Processed 11/20 samples\n",
      "[Cluster 10] Processed 16/20 samples\n",
      "[Cluster 17] Processed 1/20 samples\n",
      "[Cluster 17] Processed 6/20 samples\n",
      "[Cluster 17] Processed 11/20 samples\n",
      "[Cluster 17] Processed 16/20 samples\n",
      "[Cluster 18] Processed 1/20 samples\n",
      "[Cluster 18] Processed 6/20 samples\n",
      "[Cluster 18] Processed 11/20 samples\n",
      "[Cluster 18] Processed 16/20 samples\n",
      "[Cluster 40] Processed 1/20 samples\n",
      "[Cluster 40] Processed 6/20 samples\n",
      "[Cluster 40] Processed 11/20 samples\n",
      "[Cluster 40] Processed 16/20 samples\n",
      "[Cluster 23] Processed 1/20 samples\n",
      "[Cluster 23] Processed 6/20 samples\n",
      "[Cluster 23] Processed 11/20 samples\n",
      "[Cluster 23] Processed 16/20 samples\n",
      "[Cluster 21] Processed 1/20 samples\n",
      "[Cluster 21] Processed 6/20 samples\n",
      "[Cluster 21] Processed 11/20 samples\n",
      "[Cluster 21] Processed 16/20 samples\n",
      "[Cluster 43] Processed 1/20 samples\n",
      "[Cluster 43] Processed 6/20 samples\n",
      "[Cluster 43] Processed 11/20 samples\n",
      "[Cluster 43] Processed 16/20 samples\n",
      "[Cluster 24] Processed 1/20 samples\n",
      "[Cluster 24] Processed 6/20 samples\n",
      "[Cluster 24] Processed 11/20 samples\n",
      "[Cluster 24] Processed 16/20 samples\n",
      "[Cluster 38] Processed 1/20 samples\n",
      "[Cluster 38] Processed 6/20 samples\n",
      "[Cluster 38] Processed 11/20 samples\n",
      "[Cluster 38] Processed 16/20 samples\n",
      "[Cluster 36] Processed 1/20 samples\n",
      "[Cluster 36] Processed 6/20 samples\n",
      "[Cluster 36] Processed 11/20 samples\n",
      "[Cluster 36] Processed 16/20 samples\n",
      "[Cluster 11] Processed 1/20 samples\n",
      "[Cluster 11] Processed 6/20 samples\n",
      "[Cluster 11] Processed 11/20 samples\n",
      "[Cluster 11] Processed 16/20 samples\n",
      "[Cluster 26] Processed 1/20 samples\n",
      "[Cluster 26] Processed 6/20 samples\n",
      "[Cluster 26] Processed 11/20 samples\n",
      "[Cluster 26] Processed 16/20 samples\n",
      "[Cluster 34] Processed 1/20 samples\n",
      "[Cluster 34] Processed 6/20 samples\n",
      "[Cluster 34] Processed 11/20 samples\n",
      "[Cluster 34] Processed 16/20 samples\n",
      "[Cluster 37] Processed 1/20 samples\n",
      "[Cluster 37] Processed 6/20 samples\n",
      "[Cluster 37] Processed 11/20 samples\n",
      "[Cluster 37] Processed 16/20 samples\n",
      "[Cluster 28] Processed 1/20 samples\n",
      "[Cluster 28] Processed 6/20 samples\n",
      "[Cluster 28] Processed 11/20 samples\n",
      "[Cluster 28] Processed 16/20 samples\n",
      "[Cluster 30] Processed 1/20 samples\n",
      "[Cluster 30] Processed 6/20 samples\n",
      "[Cluster 30] Processed 11/20 samples\n",
      "[Cluster 30] Processed 16/20 samples\n",
      "[Cluster 27] Processed 1/20 samples\n",
      "[Cluster 27] Processed 6/20 samples\n",
      "[Cluster 27] Processed 11/20 samples\n",
      "[Cluster 27] Processed 16/20 samples\n",
      "[Cluster 42] Processed 1/20 samples\n",
      "[Cluster 42] Processed 6/20 samples\n",
      "[Cluster 42] Processed 11/20 samples\n",
      "[Cluster 42] Processed 16/20 samples\n",
      "[Cluster 47] Processed 1/20 samples\n",
      "[Cluster 47] Processed 6/20 samples\n",
      "[Cluster 47] Processed 11/20 samples\n",
      "[Cluster 47] Processed 16/20 samples\n",
      "[Cluster 45] Processed 1/20 samples\n",
      "[Cluster 45] Processed 6/20 samples\n",
      "[Cluster 45] Processed 11/20 samples\n",
      "[Cluster 45] Processed 16/20 samples\n",
      "[Cluster 44] Processed 1/20 samples\n",
      "[Cluster 44] Processed 6/20 samples\n",
      "[Cluster 44] Processed 11/20 samples\n",
      "[Cluster 44] Processed 16/20 samples\n",
      "[Cluster 31] Processed 1/20 samples\n",
      "[Cluster 31] Processed 6/20 samples\n",
      "[Cluster 31] Processed 11/20 samples\n",
      "[Cluster 31] Processed 16/20 samples\n",
      "[Cluster 48] Processed 1/20 samples\n",
      "[Cluster 48] Processed 6/20 samples\n",
      "[Cluster 48] Processed 11/20 samples\n",
      "[Cluster 48] Processed 16/20 samples\n",
      "[Cluster 46] Processed 1/20 samples\n",
      "[Cluster 46] Processed 6/20 samples\n",
      "[Cluster 46] Processed 11/20 samples\n",
      "[Cluster 46] Processed 16/20 samples\n",
      "[Cluster 1004] Processed 1/20 samples\n",
      "[Cluster 1004] Processed 6/20 samples\n",
      "[Cluster 1004] Processed 11/20 samples\n",
      "[Cluster 1004] Processed 16/20 samples\n",
      "[Cluster 1014] Processed 1/20 samples\n",
      "[Cluster 1014] Processed 6/20 samples\n",
      "[Cluster 1014] Processed 11/20 samples\n",
      "[Cluster 1014] Processed 16/20 samples\n",
      "[Cluster 1006] Processed 1/20 samples\n",
      "[Cluster 1006] Processed 6/20 samples\n",
      "[Cluster 1006] Processed 11/20 samples\n",
      "[Cluster 1006] Processed 16/20 samples\n",
      "[Cluster 1013] Processed 1/20 samples\n",
      "[Cluster 1013] Processed 6/20 samples\n",
      "[Cluster 1013] Processed 11/20 samples\n",
      "[Cluster 1013] Processed 16/20 samples\n",
      "[Cluster 1002] Processed 1/20 samples\n",
      "[Cluster 1002] Processed 6/20 samples\n",
      "[Cluster 1002] Processed 11/20 samples\n",
      "[Cluster 1002] Processed 16/20 samples\n",
      "[Cluster 1008] Processed 1/20 samples\n",
      "[Cluster 1008] Processed 6/20 samples\n",
      "[Cluster 1008] Processed 11/20 samples\n",
      "[Cluster 1008] Processed 16/20 samples\n",
      "[Cluster 1001] Processed 1/20 samples\n",
      "[Cluster 1001] Processed 6/20 samples\n",
      "[Cluster 1001] Processed 11/20 samples\n",
      "[Cluster 1001] Processed 16/20 samples\n",
      "[Cluster 1007] Processed 1/20 samples\n",
      "[Cluster 1007] Processed 6/20 samples\n",
      "[Cluster 1007] Processed 11/20 samples\n",
      "[Cluster 1007] Processed 16/20 samples\n",
      "[Cluster 1020] Processed 1/20 samples\n",
      "[Cluster 1020] Processed 6/20 samples\n",
      "[Cluster 1020] Processed 11/20 samples\n",
      "[Cluster 1020] Processed 16/20 samples\n",
      "[Cluster 1000] Processed 1/20 samples\n",
      "[Cluster 1000] Processed 6/20 samples\n",
      "[Cluster 1000] Processed 11/20 samples\n",
      "[Cluster 1000] Processed 16/20 samples\n",
      "[Cluster 1015] Processed 1/20 samples\n",
      "[Cluster 1015] Processed 6/20 samples\n",
      "[Cluster 1015] Processed 11/20 samples\n",
      "[Cluster 1015] Processed 16/20 samples\n",
      "[Cluster 1022] Processed 1/20 samples\n",
      "[Cluster 1022] Processed 6/20 samples\n",
      "[Cluster 1022] Processed 11/20 samples\n",
      "[Cluster 1022] Processed 16/20 samples\n",
      "[Cluster 1018] Processed 1/20 samples\n",
      "[Cluster 1018] Processed 6/20 samples\n",
      "[Cluster 1018] Processed 11/20 samples\n",
      "[Cluster 1018] Processed 16/20 samples\n",
      "[Cluster 1039] Processed 1/20 samples\n",
      "[Cluster 1039] Processed 6/20 samples\n",
      "[Cluster 1039] Processed 11/20 samples\n",
      "[Cluster 1039] Processed 16/20 samples\n",
      "[Cluster 1021] Processed 1/20 samples\n",
      "[Cluster 1021] Processed 6/20 samples\n",
      "[Cluster 1021] Processed 11/20 samples\n",
      "[Cluster 1021] Processed 16/20 samples\n",
      "[Cluster 1011] Processed 1/20 samples\n",
      "[Cluster 1011] Processed 6/20 samples\n",
      "[Cluster 1011] Processed 11/20 samples\n",
      "[Cluster 1011] Processed 16/20 samples\n",
      "[Cluster 1035] Processed 1/20 samples\n",
      "[Cluster 1035] Processed 6/20 samples\n",
      "[Cluster 1035] Processed 11/20 samples\n",
      "[Cluster 1035] Processed 16/20 samples\n",
      "[Cluster 1032] Processed 1/20 samples\n",
      "[Cluster 1032] Processed 6/20 samples\n",
      "[Cluster 1032] Processed 11/20 samples\n",
      "[Cluster 1032] Processed 16/20 samples\n",
      "[Cluster 1034] Processed 1/20 samples\n",
      "[Cluster 1034] Processed 6/20 samples\n",
      "[Cluster 1034] Processed 11/20 samples\n",
      "[Cluster 1034] Processed 16/20 samples\n",
      "[Cluster 1003] Processed 1/20 samples\n",
      "[Cluster 1003] Processed 6/20 samples\n",
      "[Cluster 1003] Processed 11/20 samples\n",
      "[Cluster 1003] Processed 16/20 samples\n",
      "[Cluster 1027] Processed 1/20 samples\n",
      "[Cluster 1027] Processed 6/20 samples\n",
      "[Cluster 1027] Processed 11/20 samples\n",
      "[Cluster 1027] Processed 16/20 samples\n",
      "[Cluster 1030] Processed 1/20 samples\n",
      "[Cluster 1030] Processed 6/20 samples\n",
      "[Cluster 1030] Processed 11/20 samples\n",
      "[Cluster 1030] Processed 16/20 samples\n",
      "[Cluster 1016] Processed 1/20 samples\n",
      "[Cluster 1016] Processed 6/20 samples\n",
      "[Cluster 1016] Processed 11/20 samples\n",
      "[Cluster 1016] Processed 16/20 samples\n",
      "[Cluster 1005] Processed 1/20 samples\n",
      "[Cluster 1005] Processed 6/20 samples\n",
      "[Cluster 1005] Processed 11/20 samples\n",
      "[Cluster 1005] Processed 16/20 samples\n",
      "[Cluster 1029] Processed 1/20 samples\n",
      "[Cluster 1029] Processed 6/20 samples\n",
      "[Cluster 1029] Processed 11/20 samples\n",
      "[Cluster 1029] Processed 16/20 samples\n",
      "[Cluster 1043] Processed 1/20 samples\n",
      "[Cluster 1043] Processed 6/20 samples\n",
      "[Cluster 1043] Processed 11/20 samples\n",
      "[Cluster 1043] Processed 16/20 samples\n",
      "[Cluster 1037] Processed 1/20 samples\n",
      "[Cluster 1037] Processed 6/20 samples\n",
      "[Cluster 1037] Processed 11/20 samples\n",
      "[Cluster 1037] Processed 16/20 samples\n",
      "[Cluster 1031] Processed 1/20 samples\n",
      "[Cluster 1031] Processed 6/20 samples\n",
      "[Cluster 1031] Processed 11/20 samples\n",
      "[Cluster 1031] Processed 16/20 samples\n",
      "[Cluster 1041] Processed 1/20 samples\n",
      "[Cluster 1041] Processed 6/20 samples\n",
      "[Cluster 1041] Processed 11/20 samples\n",
      "[Cluster 1041] Processed 16/20 samples\n",
      "[Cluster 1025] Processed 1/20 samples\n",
      "[Cluster 1025] Processed 6/20 samples\n",
      "[Cluster 1025] Processed 11/20 samples\n",
      "[Cluster 1025] Processed 16/20 samples\n",
      "[Cluster 1046] Processed 1/20 samples\n",
      "[Cluster 1046] Processed 6/20 samples\n",
      "[Cluster 1046] Processed 11/20 samples\n",
      "[Cluster 1046] Processed 16/20 samples\n",
      "[Cluster 1019] Processed 1/20 samples\n"
     ]
    }
   ],
   "source": [
    "#Run \n",
    "\n",
    "run_classification(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
