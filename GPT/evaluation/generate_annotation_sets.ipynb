{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation Datasets for Evaluation of LLM: GPT otuput\n",
    "- Dataframe Format: cid, text, assigned, label, annotation, mode, topic\n",
    "\n",
    "- Point: Check whether LLM-assigned labels (Politics, Waste)for individual sampled posts are correct.\n",
    "\n",
    "- 6 different sets: for each mode, set_A, set_B, agreement set (2x3), 400 total\n",
    "\n",
    "- hides assigned_label as not to influence the decision. \n",
    "\n",
    "- Used for further Inter-Annotator Agreement (Kappa score)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation sets generated in: ../../../DS_BachelorProject_PH/data/llm_subtopic/datasets/annotations\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "BASE_PATH = Path(\"../../../DS_BachelorProject_PH/data/llm_subtopic/datasets\")\n",
    "\n",
    "MULTI_PATH = BASE_PATH / \"BERTopic_posts_with_labels_multi_label.json\"\n",
    "SINGLE_PATH = BASE_PATH / \"BERTopic_posts_with_labels_single_label.json\"\n",
    "OUT_DIR = BASE_PATH / \"annotations\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# --- Parameters ---\n",
    "labels_to_sample = [\n",
    "    \"Politics\", \"Renewable\", \"Nature\", \"Activism\", \"Fossil\", \"Waste\", \n",
    "    \"Lifestyle\", \"Weather\", \"Disaster\", \"Agriculture\", \"Transportation\",\n",
    "    \"Electricity\", \"Construction\", \"Climate\", \"Technology\"\n",
    "]\n",
    "\n",
    "samples_per_label = 25\n",
    "agreement_size = 50\n",
    "\n",
    "# --- Load JSON data ---\n",
    "df_multi = pd.read_json(MULTI_PATH)\n",
    "df_single = pd.read_json(SINGLE_PATH)\n",
    "df_multi[\"mode\"] = \"multi_label\"\n",
    "df_single[\"mode\"] = \"single_label\"\n",
    "\n",
    "# --- Helper: stratified sampling by assigned_label ---\n",
    "def stratify_samples(df):\n",
    "    label_buckets = defaultdict(list)\n",
    "    for _, row in df.iterrows():\n",
    "        lbl = row[\"assigned_label\"]\n",
    "        if lbl in labels_to_sample:\n",
    "            label_buckets[lbl].append(row)\n",
    "\n",
    "    stratified = []\n",
    "    for label, rows in label_buckets.items():\n",
    "        n = min(samples_per_label, len(rows))\n",
    "        stratified.extend(random.sample(rows, n))\n",
    "    return pd.DataFrame(stratified)\n",
    "\n",
    "# --- Stratify datasets ---\n",
    "df_multi_sampled = stratify_samples(df_multi)\n",
    "df_single_sampled = stratify_samples(df_single)\n",
    "\n",
    "# --- Build agreement set (25 from each mode) ---\n",
    "df_agreement_multi = df_multi_sampled.sample(n=agreement_size // 2, random_state=42)\n",
    "df_agreement_single = df_single_sampled.sample(n=agreement_size // 2, random_state=43)\n",
    "\n",
    "# --- Remove from main sets to avoid duplication ---\n",
    "df_multi_sampled = df_multi_sampled.drop(df_agreement_multi.index)\n",
    "df_single_sampled = df_single_sampled.drop(df_agreement_single.index)\n",
    "\n",
    "# --- Split into A/B annotators ---\n",
    "def split_annotators(df, seed):\n",
    "    df = df.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "    half = len(df) // 2\n",
    "    return df.iloc[:half], df.iloc[half:]\n",
    "\n",
    "multi_A, multi_B = split_annotators(df_multi_sampled, seed=1)\n",
    "single_A, single_B = split_annotators(df_single_sampled, seed=2)\n",
    "\n",
    "# --- Add agreement samples to both annotators ---\n",
    "multi_A = pd.concat([multi_A, df_agreement_multi], ignore_index=True)\n",
    "multi_B = pd.concat([multi_B, df_agreement_multi], ignore_index=True)\n",
    "single_A = pd.concat([single_A, df_agreement_single], ignore_index=True)\n",
    "single_B = pd.concat([single_B, df_agreement_single], ignore_index=True)\n",
    "\n",
    "def format_for_annotation(df, task_type):\n",
    "    df_out = df[[\"cid\", \"text\", \"topic\", \"mode\"]].copy()\n",
    "    df_out[\"annotation\"] = \"\"\n",
    "    df_out[\"notes\"] = \"\"\n",
    "    if task_type == \"multi\":\n",
    "        df_out[\"instruction\"] = \"Correct / Partial / Incorrect\"\n",
    "    else:\n",
    "        df_out[\"instruction\"] = \"Correct / Incorrect\"\n",
    "    return df_out\n",
    "\n",
    "# JaySon\n",
    "format_for_annotation(multi_A, \"multi\").to_json(OUT_DIR / \"multi_label_set_Abel.csv\", index=False)\n",
    "format_for_annotation(multi_B, \"multi\").to_json(OUT_DIR / \"multi_label_set_Tobias.csv\", index=False)\n",
    "format_for_annotation(df_agreement_multi, \"multi\").to_csv(OUT_DIR / \"multi_label_agreement.csv\", index=False)\n",
    "\n",
    "format_for_annotation(single_A, \"single\").to_json(OUT_DIR / \"single_label_set_A.csv\", index=False)\n",
    "format_for_annotation(single_B, \"single\").to_json(OUT_DIR / \"single_label_set_B.csv\", index=False)\n",
    "format_for_annotation(df_agreement_single, \"single\").to_json(OUT_DIR / \"single_label_agreement.csv\", index=False)\n",
    "\n",
    "print(\"Annotation sets generated in:\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
