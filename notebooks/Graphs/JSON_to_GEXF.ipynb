{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert JSON files to GEXF format for Gephi Graphing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install networkx -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories to saved json files / Note: Change to using dynamic pathing or backups folder on HPC\n",
    "\n",
    "def load_json(path):\n",
    "    with open(path, \"r\", encoding= \"utf-8\") as file:\n",
    "        return json.load(file)\n",
    "\n",
    "likes_path = \"/Users/tobiasmichelsen/Bachelor_Project/DS_BachelorProject_PH/notebooks/likes_backup_2025-03-23_19-07-24.json\"\n",
    "posts_path = \"/Users/tobiasmichelsen/Bachelor_Project/DS_BachelorProject_PH/data/backups_test/posts/posts_backup_1.json\"\n",
    "follows_path = \"/Users/tobiasmichelsen/Bachelor_Project/DS_BachelorProject_PH/notebooks/follows_backup_2025-03-23_19-08-02.json\"\n",
    "reposts_path = \"/Users/tobiasmichelsen/Bachelor_Project/DS_BachelorProject_PH/notebooks/reposts_backup_2025-03-23_19-08-34.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#likes = load_json(likes_path)\n",
    "posts = load_json(posts_path)\n",
    "#follows = load_json(follows_path)\n",
    "#reposts = load_json(reposts_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    {\"repo\": \"did:plc:rmwb2eivxpcver26ueawtxcn\", \"timestamp\": \"2025-03-23T18:07:11.422Z\", \"seq\": 6894436866, \"text\": \"This is an absolute WOW!\", \\n    \"langs\": [\"en\"], \"cid\": \"bafyreicdz4pdq5m5adkr7673mgayrf4llvesnigmrjru7elso5b5qomrum\", \\n    \"uri\": \"at://did:plc:rmwb2eivxpcver26ueawtxcn/app.bsky.feed.post/3ll2tho47oc26\"}\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    {\"repo\": \"did:plc:rmwb2eivxpcver26ueawtxcn\", \"timestamp\": \"2025-03-23T18:07:11.422Z\", \"seq\": 6894436866, \"text\": \"This is an absolute WOW!\", \n",
    "    \"langs\": [\"en\"], \"cid\": \"bafyreicdz4pdq5m5adkr7673mgayrf4llvesnigmrjru7elso5b5qomrum\", \n",
    "    \"uri\": \"at://did:plc:rmwb2eivxpcver26ueawtxcn/app.bsky.feed.post/3ll2tho47oc26\"}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    # Remove control characters except newline/tab\n",
    "    return re.sub(r\"[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F]\", \"\", text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "\n",
    "user_meta = defaultdict(lambda: {\n",
    "    \"post_count\": 0,\n",
    "    \"first_post\": None,\n",
    "    \"last_post\": None,\n",
    "    \"langs\": set(),\n",
    "    \"sample_texts\": []\n",
    "})\n",
    "\n",
    "# Extract key fields from posts: \n",
    "\n",
    "for post in posts:\n",
    "    did = post.get(\"repo\")\n",
    "    timestamp = post.get(\"timestamp\")\n",
    "    langs = post.get(\"langs\") or []\n",
    "    text = post.get(\"text\") or \"\"\n",
    "    cid = post.get(\"cid\")\n",
    "    uri = post.get(\"uri\")\n",
    "\n",
    "# If no author, we skip the post. \n",
    "    if not did or not cid:\n",
    "        continue\n",
    "\n",
    "    meta = user_meta[did]\n",
    "    meta[\"post_count\"] += 1\n",
    "    meta[\"langs\"].update(langs)\n",
    "    if text and len(meta[\"sample_texts\"]) < 3: #Change this part as it only shows up to 3 texts\n",
    "        meta[\"sample_texts\"].append(text.strip())\n",
    "\n",
    "# Parse timestamp. We first convert to datetime for python and later on back to ISO for GEFX / Gephi\n",
    "    try:\n",
    "        ts = datetime.fromisoformat(timestamp.replace(\"Z\", \"+00:00\"))\n",
    "        if not meta[\"first_post\"] or ts < meta[\"first_post\"]:\n",
    "            meta[\"first_post\"] = ts\n",
    "        if not meta[\"last_post\"] or ts > meta[\"last_post\"]:\n",
    "            meta[\"last_post\"] = ts\n",
    "    except Exception:\n",
    "        ts = None\n",
    "        \n",
    "    G.add_node(\n",
    "        cid,\n",
    "        label=f\"post:{cid[:6]}...\",\n",
    "        type=\"post\",\n",
    "        author=did,\n",
    "        timestamp=timestamp or \"\",\n",
    "        text=clean_text(text[:100].strip()),\n",
    "        langs=\", \".join(langs),\n",
    "        uri=uri\n",
    "    )\n",
    "    \n",
    "    G.add_edge(\n",
    "    did,\n",
    "    cid,\n",
    "    label=\"authored\",\n",
    "    timestamp=timestamp or \"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEXF saved to posts_with_edges.gexf with 18063 nodes and 9999 edges.\n"
     ]
    }
   ],
   "source": [
    "for did, meta in user_meta.items():\n",
    "    G.add_node(\n",
    "        did,\n",
    "        label=did,\n",
    "        type=\"user\",\n",
    "        post_count=meta[\"post_count\"],\n",
    "        first_post=meta[\"first_post\"].isoformat() if meta[\"first_post\"] else \"\",\n",
    "        last_post=meta[\"last_post\"].isoformat() if meta[\"last_post\"] else \"\",\n",
    "        langs=\", \".join(meta[\"langs\"]),\n",
    "        sample_texts=\" | \".join(meta[\"sample_texts\"])\n",
    "    )\n",
    "\n",
    "# --- Export to GEXF ---\n",
    "output_path = \"posts_with_edges.gexf\"\n",
    "nx.write_gexf(G, output_path)\n",
    "print(f\"GEXF saved to {output_path} with {len(G.nodes)} nodes and {len(G.edges)} edges.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find length of posts: \n",
    "len(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEXF saved to user_follow_graph.gexf with 19137 nodes and 9968 edges.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# --- Utility to clean text for GEXF compatibility ---\n",
    "def clean_text(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    return re.sub(r\"[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F]\", \"\", text)\n",
    "\n",
    "# --- Load your JSON files ---\n",
    "def load_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# Update these paths as needed\n",
    "posts_path = \"/Users/tobiasmichelsen/Bachelor_Project/DS_BachelorProject_PH/data/backups_test/posts/posts_backup_1.json\"\n",
    "follows_path = \"/Users/tobiasmichelsen/Bachelor_Project/DS_BachelorProject_PH/data/backups_test/follows/follows_backup_1.json\"\n",
    "\n",
    "posts = load_json(posts_path)\n",
    "follows = load_json(follows_path)\n",
    "\n",
    "# --- Initialize directed graph ---\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# --- Collect user metadata from posts ---\n",
    "user_meta = defaultdict(lambda: {\n",
    "    \"post_count\": 0,\n",
    "    \"first_post\": None,\n",
    "    \"last_post\": None,\n",
    "    \"langs\": set(),\n",
    "    \"sample_texts\": []\n",
    "})\n",
    "\n",
    "for post in posts:\n",
    "    did = post.get(\"repo\")\n",
    "    timestamp = post.get(\"timestamp\")\n",
    "    langs = post.get(\"langs\") or []\n",
    "    text = post.get(\"text\") or \"\"\n",
    "\n",
    "    if not did:\n",
    "        continue\n",
    "\n",
    "    meta = user_meta[did]\n",
    "    meta[\"post_count\"] += 1\n",
    "    meta[\"langs\"].update(langs)\n",
    "    if text and len(meta[\"sample_texts\"]) < 3:\n",
    "        meta[\"sample_texts\"].append(clean_text(text.strip()))\n",
    "\n",
    "    try:\n",
    "        ts = datetime.fromisoformat(timestamp.replace(\"Z\", \"+00:00\"))\n",
    "        if not meta[\"first_post\"] or ts < meta[\"first_post\"]:\n",
    "            meta[\"first_post\"] = ts\n",
    "        if not meta[\"last_post\"] or ts > meta[\"last_post\"]:\n",
    "            meta[\"last_post\"] = ts\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# --- Add users from posts ---\n",
    "for did, meta in user_meta.items():\n",
    "    G.add_node(\n",
    "        did,\n",
    "        label=did,\n",
    "        type=\"user\",\n",
    "        post_count=meta[\"post_count\"],\n",
    "        first_post=meta[\"first_post\"].isoformat() if meta[\"first_post\"] else \"\",\n",
    "        last_post=meta[\"last_post\"].isoformat() if meta[\"last_post\"] else \"\",\n",
    "        langs=\", \".join(meta[\"langs\"]),\n",
    "        sample_texts=\" | \".join(meta[\"sample_texts\"])\n",
    "    )\n",
    "\n",
    "# --- Add users from follows (ensure both ends are nodes) ---\n",
    "for follow in follows:\n",
    "    source = follow.get(\"repo\")            # Follower\n",
    "    target = follow.get(\"followed_user\")   # Followed\n",
    "\n",
    "    if not source or not target:\n",
    "        continue\n",
    "\n",
    "    for did in [source, target]:\n",
    "        if did not in G.nodes:\n",
    "            G.add_node(did, label=did, type=\"user\")\n",
    "\n",
    "    G.add_edge(source, target, label=\"follows\", timestamp=follow.get(\"timestamp\", \"\"))\n",
    "\n",
    "# --- Export to GEXF ---\n",
    "output_path = \"user_follow_graph.gexf\"\n",
    "nx.write_gexf(G, output_path)\n",
    "print(f\"GEXF saved to {output_path} with {len(G.nodes)} nodes and {len(G.edges)} edges.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ToDo: Save to data/gexf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
